{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "169c6a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_openai import ChatOpenAI\n",
    "from typing import TypedDict\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langgraph.graph import add_messages\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from mcp import ClientSession, StdioServerParameters\n",
    "from mcp.client.stdio import stdio_client\n",
    "from langchain_mcp_adapters.tools import load_mcp_tools\n",
    "from langchain_core.messages import ToolMessage\n",
    "from typing import Annotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9f92906",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3af4510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# server_params = StdioServerParameters(\n",
    "#     command=\"python\",\n",
    "#     args = [\"/Users/lakshitagarwal/Hivel/mcp-server/pr_mcp_server.py\"],\n",
    "#     env = None\n",
    "# )\n",
    "# async def init_mcp():\n",
    "#     \"\"\"Initialize MCP connection and load tools\"\"\"\n",
    "#     async with stdio_client(server_params) as (read, write):\n",
    "#         async with ClientSession(read, write) as session:\n",
    "#             await session.initialize()\n",
    "#             tools = await load_mcp_tools(session)\n",
    "#             return tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54db87e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_query\n",
      "get_pr_summary\n",
      "list_tables\n",
      "safe_sql\n"
     ]
    }
   ],
   "source": [
    "server_params = StdioServerParameters(\n",
    "    command=\"python\",\n",
    "    args=[\"/Users/lakshitagarwal/Hivel/mcp-server/pr_mcp_server.py\"], \n",
    "    env=None\n",
    ")\n",
    "\n",
    "mcp_client = None\n",
    "mcp_session = None\n",
    "mcp_tools = None\n",
    "\n",
    "async def init_mcp():\n",
    "    \"\"\"Initialize MCP connection and load tools\"\"\"\n",
    "    global mcp_client, mcp_session, mcp_tools\n",
    "    \n",
    "    # Create client\n",
    "    mcp_client = stdio_client(server_params)\n",
    "    read, write = await mcp_client.__aenter__()\n",
    "    \n",
    "    # Create session\n",
    "    mcp_session = ClientSession(read, write)\n",
    "    await mcp_session.__aenter__()\n",
    "    await mcp_session.initialize()\n",
    "    \n",
    "    # Load tools\n",
    "    mcp_tools = await load_mcp_tools(mcp_session)\n",
    "    for tool in mcp_tools:\n",
    "        print(tool.name)\n",
    "    \n",
    "    return mcp_tools\n",
    "\n",
    "tools = await init_mcp()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6c55761",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85f48d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# state\n",
    "class chatState(TypedDict):\n",
    "    messages: Annotated[list[BaseMessage], add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9a58db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# func\n",
    "def chat_node(state: chatState) -> chatState:\n",
    "    messages = state[\"messages\"]\n",
    "    res = llm_with_tools.invoke(messages)\n",
    "    return {\"messages\": [res]}\n",
    "\n",
    "async def tool_node(state: chatState) -> chatState:\n",
    "    \"\"\"Execute any tool calls from the last message\"\"\"\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    \n",
    "    if not hasattr(last_message, 'tool_calls') or not last_message.tool_calls:\n",
    "        return {\"messages\": []}\n",
    "    \n",
    "    tool_messages = []\n",
    "    for tool_call in last_message.tool_calls:\n",
    "        # Find the matching tool\n",
    "        matching_tool = None\n",
    "        for tool in tools:\n",
    "            if tool.name == tool_call[\"name\"]:\n",
    "                matching_tool = tool\n",
    "                break\n",
    "        \n",
    "        if matching_tool:\n",
    "                result = await matching_tool.ainvoke(tool_call[\"args\"])\n",
    "                tool_messages.append(\n",
    "                    ToolMessage(\n",
    "                        content=str(result),\n",
    "                        tool_call_id=tool_call[\"id\"]\n",
    "                    )\n",
    "                )\n",
    "        else:\n",
    "            # Tool not found - still need to respond to maintain message flow\n",
    "            tool_messages.append(\n",
    "                ToolMessage(\n",
    "                    content=f\"Error: Tool '{tool_call['name']}' not found\",\n",
    "                    tool_call_id=tool_call[\"id\"]\n",
    "                )\n",
    "            )\n",
    "    return {\"messages\": tool_messages}\n",
    "\n",
    "def should_continue(state: chatState) -> str:\n",
    "    \"\"\"Decide: continue to tools or end?\"\"\"\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if hasattr(last_message, 'tool_calls') and last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    return \"end\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "357a38cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkptr = MemorySaver()\n",
    "\n",
    "graph = StateGraph(chatState)\n",
    "graph.add_node(\"chat_node\", chat_node)\n",
    "graph.add_node(\"tools\", tool_node)\n",
    "\n",
    "graph.add_edge(START, \"chat_node\")\n",
    "graph.add_conditional_edges(\n",
    "    \"chat_node\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"tools\": \"tools\",\n",
    "        \"end\": END\n",
    "    })\n",
    "graph.add_edge(\"tools\", \"chat_node\")\n",
    "\n",
    "workflow = graph.compile(checkpointer=checkptr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16679346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x12d98f8f0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4ba640a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# intial_state = {\"messages\": [HumanMessage(content=\"Hello, how are you?\")]}\n",
    "# workflow.invoke(intial_state)[\"messages\"][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4bb8cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM: You asked me to tell you the five tables with the most rows in your database. If you have any further questions or need more assistance, feel free to ask!\n",
      "LLM: Here are the five tables with the most rows in your database:\n",
      "\n",
      "1. **task_alerts**: 1,220,441 rows\n",
      "2. **pull_request**: 92,041 rows\n",
      "3. **webhook_process_logs**: 96,165 rows\n",
      "4. **pr_update**: 19,764 rows\n",
      "5. **pr_commit_relation**: 12,505 rows\n",
      "\n",
      "If you need more details or assistance, let me know!\n",
      "LLM: Here are the column counts for each of the five tables:\n",
      "\n",
      "1. **task_alerts**: 5 columns\n",
      "2. **pull_request**: 75 columns\n",
      "3. **webhook_process_logs**: 10 columns\n",
      "4. **pr_update**: 15 columns\n",
      "5. **pr_commit_relation**: 7 columns\n",
      "\n",
      "Among these, the **pull_request** table has the most columns with a total of 75 columns. If you need any further information, just let me know!\n"
     ]
    },
    {
     "ename": "ToolException",
     "evalue": "Error executing tool run_query: relation \"pull_request\" does not exist\nLINE 1: ...CT author_id, COUNT(*) as pull_request_count FROM pull_reque...\n                                                             ^\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mToolException\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m      8\u001b[39m config = {\u001b[33m\"\u001b[39m\u001b[33mconfigurable\u001b[39m\u001b[33m\"\u001b[39m: {\u001b[33m\"\u001b[39m\u001b[33mthread_id\u001b[39m\u001b[33m\"\u001b[39m: thread_id}}\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m res = \u001b[38;5;28;01mawait\u001b[39;00m workflow.ainvoke({\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: [HumanMessage(content=user_inp)]}, config=config)\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLLM: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mres[\u001b[33m'\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m'\u001b[39m][-\u001b[32m1\u001b[39m].content\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Hivel/mcp-server/.venv/lib/python3.12/site-packages/langgraph/pregel/main.py:3182\u001b[39m, in \u001b[36mPregel.ainvoke\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[39m\n\u001b[32m   3179\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   3180\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m3182\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.astream(\n\u001b[32m   3183\u001b[39m     \u001b[38;5;28minput\u001b[39m,\n\u001b[32m   3184\u001b[39m     config,\n\u001b[32m   3185\u001b[39m     context=context,\n\u001b[32m   3186\u001b[39m     stream_mode=[\u001b[33m\"\u001b[39m\u001b[33mupdates\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mvalues\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   3187\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode == \u001b[33m\"\u001b[39m\u001b[33mvalues\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   3188\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m stream_mode,\n\u001b[32m   3189\u001b[39m     print_mode=print_mode,\n\u001b[32m   3190\u001b[39m     output_keys=output_keys,\n\u001b[32m   3191\u001b[39m     interrupt_before=interrupt_before,\n\u001b[32m   3192\u001b[39m     interrupt_after=interrupt_after,\n\u001b[32m   3193\u001b[39m     durability=durability,\n\u001b[32m   3194\u001b[39m     **kwargs,\n\u001b[32m   3195\u001b[39m ):\n\u001b[32m   3196\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode == \u001b[33m\"\u001b[39m\u001b[33mvalues\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   3197\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(chunk) == \u001b[32m2\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Hivel/mcp-server/.venv/lib/python3.12/site-packages/langgraph/pregel/main.py:3000\u001b[39m, in \u001b[36mPregel.astream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2998\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m loop.amatch_cached_writes():\n\u001b[32m   2999\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m3000\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner.atick(\n\u001b[32m   3001\u001b[39m     [t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m loop.tasks.values() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t.writes],\n\u001b[32m   3002\u001b[39m     timeout=\u001b[38;5;28mself\u001b[39m.step_timeout,\n\u001b[32m   3003\u001b[39m     get_waiter=get_waiter,\n\u001b[32m   3004\u001b[39m     schedule_task=loop.aaccept_push,\n\u001b[32m   3005\u001b[39m ):\n\u001b[32m   3006\u001b[39m     \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[32m   3007\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m _output(\n\u001b[32m   3008\u001b[39m         stream_mode,\n\u001b[32m   3009\u001b[39m         print_mode,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3012\u001b[39m         asyncio.QueueEmpty,\n\u001b[32m   3013\u001b[39m     ):\n\u001b[32m   3014\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m o\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Hivel/mcp-server/.venv/lib/python3.12/site-packages/langgraph/pregel/_runner.py:304\u001b[39m, in \u001b[36mPregelRunner.atick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    302\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    303\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m304\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m arun_with_retry(\n\u001b[32m    305\u001b[39m         t,\n\u001b[32m    306\u001b[39m         retry_policy,\n\u001b[32m    307\u001b[39m         stream=\u001b[38;5;28mself\u001b[39m.use_astream,\n\u001b[32m    308\u001b[39m         configurable={\n\u001b[32m    309\u001b[39m             CONFIG_KEY_CALL: partial(\n\u001b[32m    310\u001b[39m                 _acall,\n\u001b[32m    311\u001b[39m                 weakref.ref(t),\n\u001b[32m    312\u001b[39m                 stream=\u001b[38;5;28mself\u001b[39m.use_astream,\n\u001b[32m    313\u001b[39m                 retry_policy=retry_policy,\n\u001b[32m    314\u001b[39m                 futures=weakref.ref(futures),\n\u001b[32m    315\u001b[39m                 schedule_task=schedule_task,\n\u001b[32m    316\u001b[39m                 submit=\u001b[38;5;28mself\u001b[39m.submit,\n\u001b[32m    317\u001b[39m                 loop=loop,\n\u001b[32m    318\u001b[39m             ),\n\u001b[32m    319\u001b[39m         },\n\u001b[32m    320\u001b[39m     )\n\u001b[32m    321\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    322\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Hivel/mcp-server/.venv/lib/python3.12/site-packages/langgraph/pregel/_retry.py:137\u001b[39m, in \u001b[36marun_with_retry\u001b[39m\u001b[34m(task, retry_policy, stream, match_cached_writes, configurable)\u001b[39m\n\u001b[32m    135\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    136\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m task.proc.ainvoke(task.input, config)\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    139\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Hivel/mcp-server/.venv/lib/python3.12/site-packages/langgraph/_internal/_runnable.py:705\u001b[39m, in \u001b[36mRunnableSeq.ainvoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    703\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    704\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m705\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[38;5;28;01mawait\u001b[39;00m asyncio.create_task(\n\u001b[32m    706\u001b[39m             step.ainvoke(\u001b[38;5;28minput\u001b[39m, config, **kwargs), context=context\n\u001b[32m    707\u001b[39m         )\n\u001b[32m    708\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    709\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[38;5;28;01mawait\u001b[39;00m step.ainvoke(\u001b[38;5;28minput\u001b[39m, config, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Hivel/mcp-server/.venv/lib/python3.12/site-packages/langgraph/_internal/_runnable.py:473\u001b[39m, in \u001b[36mRunnableCallable.ainvoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    471\u001b[39m         \u001b[38;5;28;01mawait\u001b[39;00m run_manager.on_chain_end(ret)\n\u001b[32m    472\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m473\u001b[39m     ret = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.afunc(*args, **kwargs)\n\u001b[32m    474\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    475\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m ret.ainvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 24\u001b[39m, in \u001b[36mtool_node\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m     21\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m matching_tool:\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m         result = \u001b[38;5;28;01mawait\u001b[39;00m matching_tool.ainvoke(tool_call[\u001b[33m\"\u001b[39m\u001b[33margs\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     25\u001b[39m         tool_messages.append(\n\u001b[32m     26\u001b[39m             ToolMessage(\n\u001b[32m     27\u001b[39m                 content=\u001b[38;5;28mstr\u001b[39m(result),\n\u001b[32m     28\u001b[39m                 tool_call_id=tool_call[\u001b[33m\"\u001b[39m\u001b[33mid\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     29\u001b[39m             )\n\u001b[32m     30\u001b[39m         )\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     32\u001b[39m     \u001b[38;5;66;03m# Tool not found - still need to respond to maintain message flow\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Hivel/mcp-server/.venv/lib/python3.12/site-packages/langchain_core/tools/structured.py:63\u001b[39m, in \u001b[36mStructuredTool.ainvoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.coroutine:\n\u001b[32m     60\u001b[39m     \u001b[38;5;66;03m# If the tool does not implement async, fall back to default implementation\u001b[39;00m\n\u001b[32m     61\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m run_in_executor(config, \u001b[38;5;28mself\u001b[39m.invoke, \u001b[38;5;28minput\u001b[39m, config, **kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().ainvoke(\u001b[38;5;28minput\u001b[39m, config, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Hivel/mcp-server/.venv/lib/python3.12/site-packages/langchain_core/tools/base.py:608\u001b[39m, in \u001b[36mBaseTool.ainvoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    600\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    601\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mainvoke\u001b[39m(\n\u001b[32m    602\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    605\u001b[39m     **kwargs: Any,\n\u001b[32m    606\u001b[39m ) -> Any:\n\u001b[32m    607\u001b[39m     tool_input, kwargs = _prep_run_args(\u001b[38;5;28minput\u001b[39m, config, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m608\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.arun(tool_input, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Hivel/mcp-server/.venv/lib/python3.12/site-packages/langchain_core/tools/base.py:1030\u001b[39m, in \u001b[36mBaseTool.arun\u001b[39m\u001b[34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[39m\n\u001b[32m   1028\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m error_to_raise:\n\u001b[32m   1029\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m run_manager.on_tool_error(error_to_raise)\n\u001b[32m-> \u001b[39m\u001b[32m1030\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m error_to_raise\n\u001b[32m   1032\u001b[39m output = _format_output(content, artifact, tool_call_id, \u001b[38;5;28mself\u001b[39m.name, status)\n\u001b[32m   1033\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m run_manager.on_tool_end(output, color=color, name=\u001b[38;5;28mself\u001b[39m.name, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Hivel/mcp-server/.venv/lib/python3.12/site-packages/langchain_core/tools/base.py:999\u001b[39m, in \u001b[36mBaseTool.arun\u001b[39m\u001b[34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[39m\n\u001b[32m    996\u001b[39m         tool_kwargs[config_param] = config\n\u001b[32m    998\u001b[39m     coro = \u001b[38;5;28mself\u001b[39m._arun(*tool_args, **tool_kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m999\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m coro_with_context(coro, context)\n\u001b[32m   1000\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.response_format == \u001b[33m\"\u001b[39m\u001b[33mcontent_and_artifact\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1001\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(response) != \u001b[32m2\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Hivel/mcp-server/.venv/lib/python3.12/site-packages/langchain_core/tools/structured.py:117\u001b[39m, in \u001b[36mStructuredTool._arun\u001b[39m\u001b[34m(self, config, run_manager, *args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m config_param := _get_runnable_config_param(\u001b[38;5;28mself\u001b[39m.coroutine):\n\u001b[32m    116\u001b[39m         kwargs[config_param] = config\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.coroutine(*args, **kwargs)\n\u001b[32m    119\u001b[39m \u001b[38;5;66;03m# If self.coroutine is None, then this will delegate to the default\u001b[39;00m\n\u001b[32m    120\u001b[39m \u001b[38;5;66;03m# implementation which is expected to delegate to _run on a separate thread.\u001b[39;00m\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()._arun(\n\u001b[32m    122\u001b[39m     *args, config=config, run_manager=run_manager, **kwargs\n\u001b[32m    123\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Hivel/mcp-server/.venv/lib/python3.12/site-packages/langchain_mcp_adapters/tools.py:292\u001b[39m, in \u001b[36mconvert_mcp_tool_to_langchain_tool.<locals>.call_tool\u001b[39m\u001b[34m(**arguments)\u001b[39m\n\u001b[32m    283\u001b[39m request = MCPToolCallRequest(\n\u001b[32m    284\u001b[39m     name=tool.name,\n\u001b[32m    285\u001b[39m     args=arguments,\n\u001b[32m   (...)\u001b[39m\u001b[32m    288\u001b[39m     runtime=runtime,\n\u001b[32m    289\u001b[39m )\n\u001b[32m    290\u001b[39m call_tool_result = \u001b[38;5;28;01mawait\u001b[39;00m handler(request)\n\u001b[32m--> \u001b[39m\u001b[32m292\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_convert_call_tool_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcall_tool_result\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Hivel/mcp-server/.venv/lib/python3.12/site-packages/langchain_mcp_adapters/tools.py:80\u001b[39m, in \u001b[36m_convert_call_tool_result\u001b[39m\u001b[34m(call_tool_result)\u001b[39m\n\u001b[32m     77\u001b[39m     tool_content = tool_content[\u001b[32m0\u001b[39m]\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m call_tool_result.isError:\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ToolException(tool_content)\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m tool_content, non_text_contents \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mToolException\u001b[39m: Error executing tool run_query: relation \"pull_request\" does not exist\nLINE 1: ...CT author_id, COUNT(*) as pull_request_count FROM pull_reque...\n                                                             ^\n",
      "During task with name 'tools' and id '0883f732-f8aa-a733-2ad8-293049085e91'"
     ]
    }
   ],
   "source": [
    "thread_id = '5'\n",
    "\n",
    "while True:\n",
    "    user_inp = input(\"You: \")\n",
    "    if user_inp in [\"exit\", \"bye\", \"quit\"]:\n",
    "        break\n",
    "\n",
    "    config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "    res = await workflow.ainvoke({\"messages\": [HumanMessage(content=user_inp)]}, config=config)\n",
    "    print(f\"LLM: {res['messages'][-1].content}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
