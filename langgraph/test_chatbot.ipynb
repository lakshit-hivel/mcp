{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "169c6a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_openai import ChatOpenAI\n",
    "from typing import TypedDict\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langgraph.graph import add_messages\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from mcp import ClientSession, StdioServerParameters\n",
    "from mcp.client.stdio import stdio_client\n",
    "from langchain_mcp_adapters.tools import load_mcp_tools\n",
    "from langchain_core.messages import ToolMessage\n",
    "from typing import Annotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9f92906",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a3af4510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# server_params = StdioServerParameters(\n",
    "#     command=\"python\",\n",
    "#     args = [\"/Users/lakshitagarwal/Hivel/mcp-server/pr_mcp_server.py\"],\n",
    "#     env = None\n",
    "# )\n",
    "# async def init_mcp():\n",
    "#     \"\"\"Initialize MCP connection and load tools\"\"\"\n",
    "#     async with stdio_client(server_params) as (read, write):\n",
    "#         async with ClientSession(read, write) as session:\n",
    "#             await session.initialize()\n",
    "#             tools = await load_mcp_tools(session)\n",
    "#             return tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54db87e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_query\n",
      "get_pr_summary\n",
      "list_tables\n",
      "get_table_schema\n",
      "safe_sql\n"
     ]
    }
   ],
   "source": [
    "server_params = StdioServerParameters(\n",
    "    command=\"python\",\n",
    "    args=[\"/Users/lakshitagarwal/Hivel/mcp-server/pr_mcp_server.py\"], \n",
    "    env=None\n",
    ")\n",
    "\n",
    "mcp_client = None\n",
    "mcp_session = None\n",
    "mcp_tools = None\n",
    "\n",
    "async def init_mcp():\n",
    "    \"\"\"Initialize MCP connection and load tools\"\"\"\n",
    "    global mcp_client, mcp_session, mcp_tools\n",
    "    \n",
    "    # Create client\n",
    "    mcp_client = stdio_client(server_params)\n",
    "    read, write = await mcp_client.__aenter__()\n",
    "    \n",
    "    # Create session\n",
    "    mcp_session = ClientSession(read, write)\n",
    "    await mcp_session.__aenter__()\n",
    "    await mcp_session.initialize()\n",
    "    \n",
    "    # Load tools\n",
    "    mcp_tools = await load_mcp_tools(mcp_session)\n",
    "    for tool in mcp_tools:\n",
    "        print(tool.name)\n",
    "    \n",
    "    return mcp_tools\n",
    "\n",
    "tools = await init_mcp()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6c55761",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "# System message to guide the LLM on how to use database tools\n",
    "system_message = SystemMessage(content=\"\"\"You are a helpful database assistant with access to a PostgreSQL database in the 'insightly' schema.\n",
    "\n",
    "CRITICAL: NEVER guess table or column names. ALWAYS check the schema first!\n",
    "\n",
    "MANDATORY WORKFLOW for every query:\n",
    "1. First, call list_tables() to see available tables\n",
    "2. Then, call get_table_schema(table_name) to see the actual column names and types\n",
    "3. Build your SQL query using ONLY the columns that exist in the schema\n",
    "4. Execute using safe_sql(query) - NOT run_query()\n",
    "\n",
    "REMEMBER:\n",
    "- The database uses the 'insightly' schema, so tables are in format: insightly.table_name\n",
    "- If you get a \"does not exist\" error, you MUST check the schema and retry\n",
    "- Never assume column names like 'author', 'commits', etc. - always verify with get_table_schema()\n",
    "- Build queries based on ACTUAL schema, not assumptions\"\"\")\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85f48d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# state\n",
    "class chatState(TypedDict):\n",
    "    messages: Annotated[list[BaseMessage], add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c9a58db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# func\n",
    "def chat_node(state: chatState) -> chatState:\n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    # Always prepend system message to ensure LLM follows the schema-checking workflow\n",
    "    # Check if system message is already at the start\n",
    "    if not messages or not isinstance(messages[0], SystemMessage):\n",
    "        messages = [system_message] + messages\n",
    "    \n",
    "    res = llm_with_tools.invoke(messages)\n",
    "    return {\"messages\": [res]}\n",
    "\n",
    "async def tool_node(state: chatState) -> chatState:\n",
    "    \"\"\"Execute any tool calls from the last message\"\"\"\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    \n",
    "    if not hasattr(last_message, 'tool_calls') or not last_message.tool_calls:\n",
    "        return {\"messages\": []}\n",
    "    \n",
    "    tool_messages = []\n",
    "    for tool_call in last_message.tool_calls:\n",
    "        # Find the matching tool\n",
    "        matching_tool = None\n",
    "        for tool in tools:\n",
    "            if tool.name == tool_call[\"name\"]:\n",
    "                matching_tool = tool\n",
    "                break\n",
    "        \n",
    "        if matching_tool:\n",
    "                result = await matching_tool.ainvoke(tool_call[\"args\"])\n",
    "                tool_messages.append(\n",
    "                    ToolMessage(\n",
    "                        content=str(result),\n",
    "                        tool_call_id=tool_call[\"id\"]\n",
    "                    )\n",
    "                )\n",
    "        else:\n",
    "            # Tool not found - still need to respond to maintain message flow\n",
    "            tool_messages.append(\n",
    "                ToolMessage(\n",
    "                    content=f\"Error: Tool '{tool_call['name']}' not found\",\n",
    "                    tool_call_id=tool_call[\"id\"]\n",
    "                )\n",
    "            )\n",
    "    return {\"messages\": tool_messages}\n",
    "\n",
    "def should_continue(state: chatState) -> str:\n",
    "    \"\"\"Decide: continue to tools or end?\"\"\"\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if hasattr(last_message, 'tool_calls') and last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    return \"end\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "357a38cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkptr = MemorySaver()\n",
    "\n",
    "graph = StateGraph(chatState)\n",
    "graph.add_node(\"chat_node\", chat_node)\n",
    "graph.add_node(\"tools\", tool_node)\n",
    "\n",
    "graph.add_edge(START, \"chat_node\")\n",
    "graph.add_conditional_edges(\n",
    "    \"chat_node\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"tools\": \"tools\",\n",
    "        \"end\": END\n",
    "    })\n",
    "graph.add_edge(\"tools\", \"chat_node\")\n",
    "\n",
    "workflow = graph.compile(checkpointer=checkptr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "16679346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x1287bbe90>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b4ba640a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# intial_state = {\"messages\": [HumanMessage(content=\"Hello, how are you?\")]}\n",
    "# workflow.invoke(intial_state)[\"messages\"][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b4bb8cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM: It appears that there is no cycle time recorded for the pull request with ID 30, as indicated by an empty result from the query. \n",
      "\n",
      "If you need further assistance or have any other questions, please let me know!\n",
      "LLM: It seems that there is no cycle time recorded for the pull request with ID 35 either, as the query returned an empty result. \n",
      "\n",
      "If you would like to check something else or have any further questions, feel free to ask!\n",
      "LLM: The SQL query I executed to retrieve the cycle time for the pull request with ID 35 is as follows:\n",
      "\n",
      "```sql\n",
      "SELECT cycletimeduration\n",
      "FROM insightly.pull_request\n",
      "WHERE id = 35;\n",
      "```\n",
      "\n",
      "This query is designed to select the `cycletimeduration` from the `pull_request` table where the `id` is 35. If there is anything else you would like to know or another query you would like assistance with, just let me know!\n",
      "LLM: It seems that there are no records available for the pull request with ID 35, as the query returned an empty result. \n",
      "\n",
      "If you would like to check for another pull request ID or need assistance with something else, please let me know!\n",
      "LLM: The SQL query I executed to retrieve all metrics for the pull request with ID 35 is as follows:\n",
      "\n",
      "```sql\n",
      "SELECT *\n",
      "FROM insightly.pull_request\n",
      "WHERE id = 35;\n",
      "```\n",
      "\n",
      "This query is designed to select all columns from the `pull_request` table where the `id` is 35. If you have any other questions or need further assistance, feel free to ask!\n",
      "LLM: I cannot execute a delete query or make any modifications to the database, as I can only perform read operations (SELECT queries) for safety and integrity reasons. If you need help with crafting a delete query or understanding how to use it, I can assist you with that. Please provide more details on what you want to delete, and I'll guide you!\n",
      "LLM: Here's a summary of our interaction:\n",
      "\n",
      "1. **Author with Most Commits**: You inquired about the author who made the most commits. The author was found to have 833 total commits, with an ID of 62851. However, their name and email were provided in an encoded format.\n",
      "\n",
      "2. **Open Pull Requests**: You asked if this author had any open pull requests. I attempted several queries to find this information but encountered issues due to restrictions on the SQL commands.\n",
      "\n",
      "3. **Cycle Time Inquiry**: You asked about the cycle time for pull request IDs 30 and 35. Both queries returned empty results, indicating that there were no cycle time records for those pull requests.\n",
      "\n",
      "4. **Metrics for Pull Request ID 35**: You requested all metrics for pull request ID 35, but the query returned an empty result, suggesting no records were available.\n",
      "\n",
      "5. **SQL Queries Provided**: For each of your SQL inquiries, I provided the relevant queries, essential for your reference.\n",
      "\n",
      "6. **Delete Query Limitation**: I clarified that I cannot execute a delete query or make changes to the database, as I am limited to read operations. I offered assistance in crafting a delete query if needed.\n",
      "\n",
      "If there's anything more you need or specific questions you'd like to ask, feel free to let me know!\n"
     ]
    },
    {
     "ename": "CancelledError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mCancelledError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m      8\u001b[39m config = {\u001b[33m\"\u001b[39m\u001b[33mconfigurable\u001b[39m\u001b[33m\"\u001b[39m: {\u001b[33m\"\u001b[39m\u001b[33mthread_id\u001b[39m\u001b[33m\"\u001b[39m: thread_id}}\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m res = \u001b[38;5;28;01mawait\u001b[39;00m workflow.ainvoke({\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: [HumanMessage(content=user_inp)]}, config=config)\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLLM: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mres[\u001b[33m'\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m'\u001b[39m][-\u001b[32m1\u001b[39m].content\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Hivel/mcp-server/.venv/lib/python3.12/site-packages/langgraph/pregel/main.py:3182\u001b[39m, in \u001b[36mPregel.ainvoke\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[39m\n\u001b[32m   3179\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   3180\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m3182\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.astream(\n\u001b[32m   3183\u001b[39m     \u001b[38;5;28minput\u001b[39m,\n\u001b[32m   3184\u001b[39m     config,\n\u001b[32m   3185\u001b[39m     context=context,\n\u001b[32m   3186\u001b[39m     stream_mode=[\u001b[33m\"\u001b[39m\u001b[33mupdates\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mvalues\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   3187\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode == \u001b[33m\"\u001b[39m\u001b[33mvalues\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   3188\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m stream_mode,\n\u001b[32m   3189\u001b[39m     print_mode=print_mode,\n\u001b[32m   3190\u001b[39m     output_keys=output_keys,\n\u001b[32m   3191\u001b[39m     interrupt_before=interrupt_before,\n\u001b[32m   3192\u001b[39m     interrupt_after=interrupt_after,\n\u001b[32m   3193\u001b[39m     durability=durability,\n\u001b[32m   3194\u001b[39m     **kwargs,\n\u001b[32m   3195\u001b[39m ):\n\u001b[32m   3196\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode == \u001b[33m\"\u001b[39m\u001b[33mvalues\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   3197\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(chunk) == \u001b[32m2\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Hivel/mcp-server/.venv/lib/python3.12/site-packages/langgraph/pregel/main.py:3000\u001b[39m, in \u001b[36mPregel.astream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2998\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m loop.amatch_cached_writes():\n\u001b[32m   2999\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m3000\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner.atick(\n\u001b[32m   3001\u001b[39m     [t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m loop.tasks.values() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t.writes],\n\u001b[32m   3002\u001b[39m     timeout=\u001b[38;5;28mself\u001b[39m.step_timeout,\n\u001b[32m   3003\u001b[39m     get_waiter=get_waiter,\n\u001b[32m   3004\u001b[39m     schedule_task=loop.aaccept_push,\n\u001b[32m   3005\u001b[39m ):\n\u001b[32m   3006\u001b[39m     \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[32m   3007\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m _output(\n\u001b[32m   3008\u001b[39m         stream_mode,\n\u001b[32m   3009\u001b[39m         print_mode,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3012\u001b[39m         asyncio.QueueEmpty,\n\u001b[32m   3013\u001b[39m     ):\n\u001b[32m   3014\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m o\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Hivel/mcp-server/.venv/lib/python3.12/site-packages/langgraph/pregel/_runner.py:304\u001b[39m, in \u001b[36mPregelRunner.atick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    302\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    303\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m304\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m arun_with_retry(\n\u001b[32m    305\u001b[39m         t,\n\u001b[32m    306\u001b[39m         retry_policy,\n\u001b[32m    307\u001b[39m         stream=\u001b[38;5;28mself\u001b[39m.use_astream,\n\u001b[32m    308\u001b[39m         configurable={\n\u001b[32m    309\u001b[39m             CONFIG_KEY_CALL: partial(\n\u001b[32m    310\u001b[39m                 _acall,\n\u001b[32m    311\u001b[39m                 weakref.ref(t),\n\u001b[32m    312\u001b[39m                 stream=\u001b[38;5;28mself\u001b[39m.use_astream,\n\u001b[32m    313\u001b[39m                 retry_policy=retry_policy,\n\u001b[32m    314\u001b[39m                 futures=weakref.ref(futures),\n\u001b[32m    315\u001b[39m                 schedule_task=schedule_task,\n\u001b[32m    316\u001b[39m                 submit=\u001b[38;5;28mself\u001b[39m.submit,\n\u001b[32m    317\u001b[39m                 loop=loop,\n\u001b[32m    318\u001b[39m             ),\n\u001b[32m    319\u001b[39m         },\n\u001b[32m    320\u001b[39m     )\n\u001b[32m    321\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    322\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Hivel/mcp-server/.venv/lib/python3.12/site-packages/langgraph/pregel/_retry.py:137\u001b[39m, in \u001b[36marun_with_retry\u001b[39m\u001b[34m(task, retry_policy, stream, match_cached_writes, configurable)\u001b[39m\n\u001b[32m    135\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    136\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m task.proc.ainvoke(task.input, config)\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    139\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Hivel/mcp-server/.venv/lib/python3.12/site-packages/langgraph/_internal/_runnable.py:705\u001b[39m, in \u001b[36mRunnableSeq.ainvoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    703\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    704\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m705\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[38;5;28;01mawait\u001b[39;00m asyncio.create_task(\n\u001b[32m    706\u001b[39m             step.ainvoke(\u001b[38;5;28minput\u001b[39m, config, **kwargs), context=context\n\u001b[32m    707\u001b[39m         )\n\u001b[32m    708\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    709\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[38;5;28;01mawait\u001b[39;00m step.ainvoke(\u001b[38;5;28minput\u001b[39m, config, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Hivel/mcp-server/.venv/lib/python3.12/site-packages/langgraph/_internal/_runnable.py:473\u001b[39m, in \u001b[36mRunnableCallable.ainvoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    471\u001b[39m         \u001b[38;5;28;01mawait\u001b[39;00m run_manager.on_chain_end(ret)\n\u001b[32m    472\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m473\u001b[39m     ret = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.afunc(*args, **kwargs)\n\u001b[32m    474\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    475\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m ret.ainvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Hivel/mcp-server/.venv/lib/python3.12/site-packages/langchain_core/runnables/config.py:603\u001b[39m, in \u001b[36mrun_in_executor\u001b[39m\u001b[34m(executor_or_config, func, *args, **kwargs)\u001b[39m\n\u001b[32m    599\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n\u001b[32m    601\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m executor_or_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(executor_or_config, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m    602\u001b[39m     \u001b[38;5;66;03m# Use default executor with context copied from current context\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m603\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m asyncio.get_running_loop().run_in_executor(\n\u001b[32m    604\u001b[39m         \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    605\u001b[39m         cast(\u001b[33m\"\u001b[39m\u001b[33mCallable[..., T]\u001b[39m\u001b[33m\"\u001b[39m, partial(copy_context().run, wrapper)),\n\u001b[32m    606\u001b[39m     )\n\u001b[32m    608\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m asyncio.get_running_loop().run_in_executor(executor_or_config, wrapper)\n",
      "\u001b[31mCancelledError\u001b[39m: "
     ]
    }
   ],
   "source": [
    "thread_id = '10'\n",
    "\n",
    "while True:\n",
    "    user_inp = input(\"You: \")\n",
    "    if user_inp in [\"exit\", \"bye\", \"quit\"]:\n",
    "        break\n",
    "\n",
    "    config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "    res = await workflow.ainvoke({\"messages\": [HumanMessage(content=user_inp)]}, config=config)\n",
    "    print(f\"LLM: {res['messages'][-1].content}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
